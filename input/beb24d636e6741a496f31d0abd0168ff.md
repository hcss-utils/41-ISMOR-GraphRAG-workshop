# ID: beb24d636e6741a496f31d0abd0168ff
# Title: Russian Disinformation Efforts on Social Media
# Database: Google Scholar
# Year: 2022.0
# Fulltext:
The RAND Corporation is a research organization that develops solutions to public policy challenges to help make communities throughout the world safer and more secure, healthier and more prosperous.
How are countries using social media-particularly, disinformation campaigns-to influence the competitive space? How have governments, the private sector, and civil society responded to this threat? What more can be done? And what do these developments mean for future U.S. Air Force and the joint force training and operations? 
1
• Raphael S. Cohen The research reported here was commissioned by the Air Force Special Operations Command and conducted within the Strategy and Doctrine Program of RAND Project AIR FORCE as part of the fiscal year 2019 project "Bringing Psychological Operations and Military Information Support Operations into the Joint Force: Counterinformation Campaigns in the Social Media Age," which was designed to assist the Air Force in evaluating the threat of foreign influence campaigns on social media and assessing possible Air Force, joint force, and U.S. government countermeasures.
This report should be of value to the national security community and interested members of the public, especially those with an interest in how global trends will affect the conduct of warfare. This research was completed in September 2019, before the February 2022 Russian invasion of Ukraine. It has not been subsequently revised.
RAND is committed to ethical and respectful treatment of RAND research participants and complies with all applicable laws and regulations, including the Federal Policy for the Protection of Human Subjects, also known as the "Common Rule." The research described in this report was screened and, if necessary, reviewed by RAND's Human Subjects Protection Committee, which serves as RAND's institutional review board (IRB) charged with ensuring the ethical treatment of individuals who are participants in RAND projects through observation, intervention, interaction, or use of data about them. RAND's Federalwide Assurance (FWA) for the Protection of Human Subjects (FWA00003425, effective until June 22, 2023) serves as our assurance of compliance with federal regulations.
The views of any unnamed sources are solely their own and do not represent the official policy or position of any department or agency of the U.S. government.
RAND Project AIR FORCE (PAF), a division of the RAND Corporation, is the Department of the Air Force's (DAF's) federally funded research and development center for studies and analyses, supporting both the United States Air Force and the United States Space Force. PAF provides the DAF with independent analyses of policy alterna-  3.2. Sample IRA Military Account . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1. Social Media Platform Users Over Time, in Millions of Users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Tables 
3.1
Russia is waging wide-reaching information warfare with the Western world. A significant part of its ongoing efforts takes place on social media, which Russia has employed to spread disinformation and to interfere with the internal politics of other countries, targeting varied audiences, including the U.S. military. The impact of Russia's social media activities on specific outcomes (such as votes or policy decisions) is uncertain to date, but Russian information warfare threatens to undermine the integrity of democratic processes, erode the belief in factual truths, and cause concrete harm with well-timed or sophisticated disinformation. We sought to help the U.S. Air Force (USAF) and the joint force more effectively respond to this threat. 1
We sought to better understand Russia's disinformation on social media and generate recommendations to better meet and counter this evolving threat. We relied on an analysis of Russian military literature, investigative efforts, official reports, academic and policy literature, media reporting, and expert interviews. We also conducted a case study in Ukraine, interviewing a variety of key experts in the Ukrai-nian government and in the nongovernmental sector who are involved in confronting Russian information warfare.
We conclude that:
• Russia views social media as a double-edged sword, at once harboring anxieties about social media's potential to undermine Russia's security and recognizing its advantages as a low-cost and potentially highly effective weapon of asymmetric warfare. • Russia's use of social media outside the former Soviet Union picked up most markedly in 2014, suggesting that this behavior is, in part, a response to the West's response to the Ukraine conflict. • The Russian disinformation machine has been neither well organized nor especially well resourced (contrary to some implications in popular media), and the impact of Russian efforts on the West has been uncertain. • However, even with relatively modest investments, Russian social media activity has been wide reaching, spreading disinformation and propaganda to sizable audiences across multiple platforms. • Russia appears to view its own activity as successful, so the threat posed by this activity is likely to persist-and, potentially, to grow. • Western countermeasures have raised awareness of Russian activities, but their impact on Russia's efforts has been uncertain, and Russia appears undeterred. • Moreover, Russia's social media-based information warfare is evolving. Russia is likely to continue pursuing some of the same goals and targets but is developing more-sophisticated tactics and techniques aimed at circumventing Western countermeasures.
The Air Force and/or the joint forces should consider the following:
• USAF should be mindful of Russia's perceptions when deploying assets related to military information support operations or psychological operations in areas that Russia perceives to be of strategic importance or interest. • The joint force should adopt appropriate monitoring processes to improve detection of Russian information efforts of greatest concern to the U.S. Department of Defense (e.g., those targeting members of U.S. military and associates, U.S. and North Atlantic Treaty Organization operations). • The joint force should take measures to reduce overattribution of disinformation on social media to Russia. • USAF and the joint force should train troops and their family members to expect and recognize disinformation and other information manipulation by Russian actors. • USAF and the joint force should develop policy regarding social media platforms and devices and should train and educate troops about vulnerabilities related to sharing personal data online. • USAF and the joint force should train and educate top officials about salient risks stemming from hacking and leaking information. • USAF and the joint force should foster institutional capacity for disseminating counternarratives and debunking disinformation on matters pertaining to USAF and the U.S. Department of Defense. • USAF and the joint force should maintain clear, consistent public messaging pertaining to ongoing U.S. and allied activity and matters of public controversy implicating the U.S. and allied militaries. • USAF and the joint force should work through nongovernmental organizations to debunk disinformation.
Russia is waging a wide-reaching and relentless information warfareor, to use the Russian term, information confrontation-with the Western world. In 2017, the U.S. intelligence community publicly announced that Russia interfered in the 2016 U.S. election. Although Russian influence efforts predate 2016, Russia's activities directed at the U.S. presidential election "represented a significant escalation in directness, level of activity, and scope of effort compared to previous operations aimed at U.S. elections."
1
3
4
5
Thus, in this study, we sought to better understand Russia's disinformation through social media as a way to help the U.S. Air Force (USAF) and the joint force respond more effectively to this threat. 
6
7
To conduct this study, we performed several distinct tasks using a combination of research methods. Our process is described here.
To illuminate Russian thinking about this subject, we examined official Russian strategic documents (such as the Information Security Doctrine), public statements by Russia's leaders, and publicly available Russian-language military writings pertaining to information confrontation in general and to the role of social media in particular. Importantly, Russian military and defense experts often abstain in publicly accessible formats from declaring what Russia's approach is or should be. Instead, they discuss the nature of information confrontation in the abstract, or they address their perceptions of the approaches to information warfare adopted by the United States or the West; so, we must infer their views of Russia's approach from this discussion.
To describe how Russia uses social media, we examined a wide variety of sources, supplemented with expert interviews. Sources that we examined included research and analysis by governmental bodies involved in responding to Russian information warfare (such as the North Atlantic Treaty Organization [NATO]'s Strategic Communications Centre of Excellence [StratCom CoE]) and nongovernmental organizations (NGOs), such as Bellingcat, Atlantic Council's Digital Forensics Lab (DFRLab), and Ukrainian StopFake. We also relied on a large number of media reports that have covered Russian information efforts over the past several years. Whenever possible, we rely on established, professional media outlets such as the New York Times or Washington Post. However, we are mindful of the fact that the Russian activities that are investigated and reported by major outlets might not be representative of the universe of Russian activity in this realm. In an attempt to lessen any systematic skewing that might result from reliance solely on established media sources, we also drew on lesser-known and/or foreign media outlets. In so doing, we assessed the credibility of each source sited, and caveat our claims accordingly. We supplemented printed sources with unstructured interviews conducted on an anonymous basis with subjectmatter experts, such as representatives of international organizations, the private sector, and the nonprofit, nongovernmental sector.
To offer an account of intergovernmental responses and select national responses by governments and NGOs, we relied on research and analysis by governmental bodies involved in responding to Russian information warfare, research produced by academics and policy experts, and media reports. To a limited extent, we drew on social science research in attempts to assess potential effects of specific categories of countermeasures.
Members of our research team also conducted fieldwork interviews in Kyiv, Ukraine, on an anonymous basis. Ukraine arguably has been at the forefront of Russia's disinformation effort and, because of the 2014-2015 conflict in Eastern Ukraine, also provides insight into how Russia might employ these tactics in an actual military conflict. Interviews were conducted with experts in all major state bodies involved in responding to Russian information operations, representatives of Ukraine's robust network of NGOs engaged in monitoring, debunking, and investigating Russian information warfare and/or cyber activities, representatives of the private sector (including the technology sector), and researchers. In addition, we examined the large body of publicly available research pertaining to Russia's activities in Ukraine issued by government bodies, NGOs, and individual researchers. We also drew on media reports, including Ukrainian-language sources. Again, we assessed the credibility of each source cited and caveat our claims accordingly.
In the appendix, we examine Russia's anxieties about the threat that social media presents to the regime and its interests. For this task, we drew in part on the same official and military literature employed for our other tasks, supplemented by academic and policy research. To understand the real vulnerabilities that underlie those anxieties (and to identify which of these vulnerabilities present potential opportunities for exploitation) we also drew on academic, think tank, and policy works and on media reporting on Russia under President Vladimir Putin.  In all tasks, we rely substantially on past RAND research in this area.
Numerous terms-information operations, information war, information campaigns, psychological warfare-are used in the military and civilian literature to describe Russia's activities in the informational domain. As Ulrike Franke of the Swedish Defence Research Agency notes, " [t]o the professional, some of [these terms] have precise and well-defined meanings, some of them have become non grata, and some are just vague," and " [t]o the layman, the intricacies of these terms are even less transparent." 
8
9
10
11
12
The central focus of this study is on disinformation on social media, which is just one component of Russia's broader information confrontation activities. We define both operative concepts that make up our focus. By disinformation, we mean "false, incomplete, or misleading information that is passed, fed, or confirmed to a target individual, group, or country." 
13
10
14
15
16
17
14
We cannot capture the entire domain of relevant activity. Our scope is limited geographically; we tend to focus on Russian activities aimed against the United States and Europe. We are also limited by the opaque nature of Russian efforts, which means that only disinformation and related activity that have been discovered and publicly disclosed or relayed to us in interviews can be included. Moreover, even our synthesis of the publicly known efforts might not be exhaustive in light of the significant amount of attention that many analysts, researchers, and organizations have devoted to Russia's information confrontation efforts.
Overall, this report substantiates the following arguments and conclusions. Moscow views social media as a double-edged sword. On the one hand, the novel technology adds another layer to Russia's preexisting anxieties about the West's hostile intentions and capabilities. At the same time, Russia recognizes the advantages of social media as a lowcost and potentially highly effective weapon of asymmetric warfare. Its use of this weapon outside the former Soviet Union picked up most markedly in 2014, suggesting that Russia resorted to this tool in part as a response to the West's reaction to the Ukraine conflict.
Although popular portrayals of the Russian disinformation machine sometimes imply an organized and well-resourced operation, evidence suggests that it is neither. Even with relatively modest invest-ments, however, Russian social media activity has been wide-reaching, deploying a great number of social media accounts to spread disinformation and propaganda across multiple platforms, reaching broad and varied international audiences. Whether and how the wide reach of social media activity translates into impact or success are open questions. Still, Russia's efforts have certainly raised alarm among U.S. allies and partners and prompted a variety of responses to confront and deter Russia-to largely uncertain effect. Although evidence is scarce that Russia's efforts have altered specific measurable outcomes (such as votes or political decisions), the amount of attention that Russia's efforts have received is itself a kind of success. The appearance of pervasive foreign disinformation threatens to erode trust in the media, acceptance of vital facts, and the perceived legitimacy of democratic processes.
Moreover, more-discrete adverse consequences of Russian disinformation campaigns, such as those implicating the U.S. armed forces, are entirely plausible. Thus, we recommend that USAF and the joint force improve defensive measures aimed at raising awareness and lowering the susceptibility of military members and their families to Russian disinformation and propaganda campaigns. Russia's own vulnerabilities to social media might present opportunities for offensive action to deter disinformation campaigns, but many of these hypothetical actions carry more risks than benefits. We address these issues in the appendix, but ultimately recommend that the U.S. government and the joint force focus on creating a less fertile ground for Russian disinformation.
The rest of the report proceeds as follows. In Chapter Two, we introduce the Russian conception of information confrontation, and we synthesize Russian thinking about the place of social media within that broader conception. We also examine the ways in which publicly available Russian military literature grappled with this technological advance. In Chapter Three, we focus on the practical and moredetailed aspects of Russia's information operations on social media, looking into the when, who, where, why, and how of relevant activities. In Chapter Four, we present a selective overview of countermeasures against Russia's social media-based information operations (focusing on the intergovernmental response), and their apparent or perceived consequences. In Chapter Five, we focus on the Ukrainian experience with Russia's social media-based disinformation; in Chapter Six, we synthesize key policy recommendations most relevant to the USAF Special Operations Command and the joint force. An appendix addresses Russia's own anxieties about social media and vulnerabilities that underlie these anxieties; although vulnerabilities could hypothetically be exploited by Western offensive information operations or psychological operations (PSYOPS), we generally identify weighty reason to be cautious in this regard.
Although Russian defense experts focused on information warfare from the 1990s through the early 2000s, they only tenuously grasped how advances in modern communication technologies could play a role in that warfare. A 1999 textbook by Russian Military Intelligence (GRU) on psychological warfare, for instance, frequently notes the use of television in supporting operations, although the internet is mentioned only twice. 
1
Although preoccupation with information warfare-alongside other channels of malign influence or hybrid warfare-appears recent, Russia's approach to information confrontation is rooted in its history, stretching from as early as the 15th century through the Soviet-era institutionalization of propaganda to contemporary forms of information confrontation. 
3
7
8
9
Russia's recognition that it could not compete with the West in conventional capabilities raised the importance of information confrontation for Russian military planners and the Kremlin. 
10
11
13
14
15
16
Wars & Insurgencies, Vol. 27, No. 2, March 21, 2016, p. 291. 13
15, 2015, pp. 44-45. 14
15
47, No. 2, 2017, p. 51. 16 Mikhail Novikov and Vyacheslav Ovchinnikov, "Information
17
By the onset of the Ukraine crisis in 2014, Russian experts had integrated social media platforms into its information confrontation arsenal. Russian military thinkers and experts viewed the rise of social media as a threat to Russia's security, but they also embraced it as a low-cost and potentially highly effective offensive weapon-which can help Russia redress the imbalance in military capabilities between itself and the United States and its allies.
Moscow has long believed that the United States and the West dominate traditional print and television media and that they manipulated media conglomerates during Operations Just Cause and Desert Storm and NATO activity elsewhere. 
19
20
21
23
29, April 9, 1997. 21
22 Zhilin, 2004. 
23
24
25
26
27
24
25
28
29
30
31
29
30
34
35
36
37
38
39
40
37
38
March 9, 2016. 39
41
At least according to Russian military writings, Russia vaguely perceived the offensive implications of emerging communications technology in the 1990s but began to embrace the offensive potential of social media only in the early 2000s. 
43
44
45
46
41
42
43
44
45
46
47
48
49
50
51
49
50 Kolesov, 2008. 51
53
54
56
58
59
60
• the low cost of social media operations in terms of both funds and personnel • the wide potential reach of online information operations, especially considering the growing penetration of the internet • the ability to react in real time and in places without physical presence • the deniability of social media operations, given the difficulty in distinguishing ordinary activity from state-sponsored acts of information warfare • the perception that psychological effects of online and social media are superior to those provided by traditional media because of the potential for packaging multimedia content in ways that achieve "additional emotional and psychological influence." 61
The evolution of Russian military thought on social media, both as a threat and a weapon, is intertwined with broader Russian concerns about the implications of advances in communications technology for 60 A. V. national security and domestic stability. 
62
62
Popular portrayals of the Russian disinformation machine at times imply an organized and well-resourced operation, capable of affecting behaviors and events around the world. Evidence paints a more nuanced picture: Despite its strengths, there are also distinct limitations to the power of Russia's information confrontation machine. Russia has a wider variety of official and unofficial actors to wage its information warfare than do Western countries. However, publicly available evidence indicates that these actors are not all seamlessly coordinated or particularly well funded. Although Russia has used a multitude of social media accounts to spread disinformation and propaganda on a great variety of subjects across multiple platforms and has reached broad and varied international audiences, this outreach does not equate to impact. The fullest display of Russian information warfare-with, almost certainly, the greatest impact-took place in Ukraine, where Russia integrated information and kinetic operations, using disinformation and propaganda both as strategic tools to shape political outcomes and as operational tools to undermine military morale. The impact of Russia's information operations in Western countries is less obvious and more difficult to assess. In this chapter, we examine the practical and more-detailed aspects of Russia's information operations on social media by addressing the details of Russia's information warfare, offering a sense of the scale of the activities, and providing observations on their impact.
Russia's earliest online information operations were domestic ones: During the Chechen conflict in the late 1990s, both Russian state and pro-Russian nonstate actors attacked Chechen online media and other websites. Although best described as hacking, the actions appear to have been intended to provoke informational-psychological effects. 1 Subsequently, Russians also developed their social media toolkit domestically: Since about 2011, for example, such techniques as hijacking Twitter and Facebook conversations to flood out meaningful coordination of opposition activity began to be detected. 2 A year after his reelection, Putin had reportedly tasked Igor Sergun, then head of the GRU, to begin "repurposing cyberweapons previously used for psychological operations in war zones for use in electioneering"-after which Russian intelligence agencies began funding troll farms to expand psychological warfare in cyberspace. 
3
4
5
Facebook,
Twitter,
and Instagram. 6
7
8
9
Russia's social media-based information warfare machinery involves three type of actors (Table 
3
10
12
10
11
12 VGTRK is the All-Russia State Television and Radio Broadcasting Company, which operates Russia's state television and radio channels. RT (formerly Russia Today) and Sputnik are both deeply integrated with social media. . . . RT . . . calls itself 'essentially an internet media company'. RT claims that its presence on YouTube is even higher than on TV, although this statistic might be overestimated because of RT's wish to present itself as one of the leading channels globally, as leaked documents reveal (Anna Reynolds, ed., Social Media as a Tool of Hybrid Warfare, Riga, Latvia: NATO Strategic Communications Centre of Excellence, May 2016, p. 25). trolled institutions. 
13
14
15
16
17
18
17 ODNI, 2017, p.
18
19
20
3
21
22
Even within the Russian state, an opaque shell of operational security surrounds Russia's command-and-control scheme as it relates to conducting cyber and digital influence operations. Wide discrepancies in levels of awareness and contribution likely distinguish planners from the network of operators within Russia's information confrontation machine.  Publicly available evidence suggests that the Ministry of Defense (the GRU in particular) emerged after the 2008 Georgian War as a key state actor in the domain of digital psychological warfare. 
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
September 14, 2016. 42
43 Mark Galeotti, "Russian Intelligence Is at (Political) War," NATO Review Magazine, May 12, 2017a. 
44
45
46
47
48
49
50
47
48
49 Soldatov and Borogan, 2015, p. 127
50
Revelations from a defector showed a limited online influence effort run out of the SVR's United Nations office in New York as early as the mid-1990s. 
51
52
53
54
55
56
Two sets of known state-affiliated actors play significant roles in information warfare generally and in social media in particular. The first set consists of state-sponsored media organizations-specifically, RT and Sputnik, both of which have been described as Russia's propaganda and disinformation machines. 
57
58
59
60
62
63
64
65
66
62
63 Soldatov and Borogan, 2015;
Turovsky, 2019. 64
65
66
Russia's leading oppositionist, Alexey Navalny, and other human rights activists, journalists, bloggers, film directors, and literary figures. 
67
68
69
70
71
72
73
74
75
Russians have frequently and independently supported their government through digital means, including such groups as the Siberian Network Brigade (a group of Russian university students who began launching DDoS attacks against pro-Chechen websites during the Second Chechen War), the Nashi youth movement, and other organizations that lend their support or amplify state messaging only on specific issues that resonate with that group. Although the Kremlin cannot maintain contact with all these groups, they nonetheless play an important-if ad hoc-role in Russian information efforts.
Ukrainian security experts, for example, believed that Russia's intelligence services as of early 2019 had started "outsourcing" much of their digital propaganda efforts to "younger creative people." 
76
74
75
77
78
79
80
81
82
78
79
80
81
82
There might be a level of lateral coordination among the key sets of actors (state, state-affiliated, and unaffiliated) below the level of the Kremlin. 
84
85
86
83
Soldatov and
Borogan, 2015, pp. 285-287. 84 Galeotti, 2017c. 85
December 17, 2018, p. 67. 86
88
More often, campaigns that appear coordinated consist of ad hoc-and post hoc-actions by actors seizing opportunities created by others. In Germany's notorious 2016 Lisa case, as Galeotti points out, original social media accounts of a fabricated story that a Russian-German girl was raped by Arab or Muslim immigrants were picked up by the Russian media and cited by Sergei Lavrov, Russia's foreign minister. In this case, as in many others, "initiative is taken by individual agents and actors," and the "government was simply reacting to, and trying to exploit, something that started independently." 89 But other cases suggest a lack of coordination where it should have been possible: For example, the sometimes concurrent and redundant operations of the GRU, the IRA, and APT29 in targeting the 2016 U.S. presidential election probably demonstrated some degree of disconnect. 90
Obvious difficulties arise when attempting precise determinations of the people and resources that Moscow has at its disposal specifically to spread disinformation through social media. Among these difficulties are the high levels of secrecy that Russian officials assign to influence activities and the involvement of numerous nonstate actors. As we noted in Chapter One, Russia does not firmly distinguish between cyber and information warfare or between information-technical and informationpsychological activities. Thus, when it comes to assessing the resources or capabilities used or available for disinformation on social media, we concluded that it is not possible or useful to separate the two aspects.
88 DFRLab, 2018a. 
89
Public sources containing information on the strength of Russian organizations responsible for waging information confrontation are limited, and they provide only snapshots of possible staffing levels. Unit 26165 (or the 85th Main Special Service Center), a key part of Moscow's information confrontation organization as evidenced by the U.S. Department of Justice indictments after 2016, fell during the Cold War under the GRU's Sixth Directorate, which was responsible for cryptography and signals intelligence. 
91
92
93
94
95
96
97
94
98
99
100
Importantly, Russia's shortfalls in personnel are likely mitigated by the ability of the Russian state to tap into a vast network of nonstate institutions to supplement its operations. 
102
104
105
106
As with personnel counts, details are scare regarding Russia's expenditures on information confrontation broadly or on social media-based disinformation specifically. A 2017 survey by a defense ministrylinked Russian cybersecurity firm claimed that Russia's overall budget for cyberoperations-which appear to include "information wars" and cyberattacks designed to affect the "mood and behavior" of civilian populations (along with espionage and other cyberattacks)-amounted to around $300 million annually. 
107
108
105
106
108
109
Since 2016, more public information has been made available regarding the Kremlin's budget for overt propaganda outlets and the IRA. Although these figures also include funding for traditional media, social media is an increasingly integral part of what state-affiliated media organizations do. The U.S. intelligence community in 2017 stated that the Kremlin spent $190 million annually on RT's programming and broadcasting, although other estimates are somewhat higher and the draft budget for 2020 asked for $370 million. 
110
111
112
113
114
As of October 2018, the IRA appears to have used at least 3,613 accounts to disseminate English-language and Russian-language messaging- and that is likely an underestimate because it excludes accounts that were suspected but deleted prior to Twitter's count. 
116
117
The numbers of social media accounts operated by the GRU (or the other intelligence agencies) are unknown but are in all likelihood quite a bit smaller than those affiliated with the IRA and other trolls. Both the U.S. Department of Justice indictments against GRU officers and the previously referenced report published by the DFRLab point to only a handful of fake accounts generated by GRU specialists, and most of their social media accounts only posted once before deletion. 
118
119
Although nearly all of the figures cited should be presumed to be imprecise and uncertain, they might be useful in conveying an order of magnitude. As emphasized, an apples-to-apples comparison of Russia's resources devoted to disinformation on social media with those of its rivals is not feasible. But some sense of U.S. resources might be useful to simply provide perspective-and to offer insight into Russia's perceptions of its own capabilities. The estimates of Russia's cyber and psychological warfare personnel (i.e., state actors) that we have provided are almost certainly smaller than the size of U.S. Cyber and PSYOPS forces. 
120
121
122
Such comparisons are not wholly informative about investments into social media-based information warfare in large part because, in contrast to Russia, the United States does not involve any such resources in offensive social media efforts. Nonetheless, the disparities in cyber and psychological resources likely do affect Russian perceptions of those capabilities. There is evidence that, whatever the facts of the matter, Russia perceives its information-warfare arsenal generally to be smaller than those of other states and those of the United States in particular. For example, a Russian information security company, which lists the defense ministry as a client, published a report that said that the U.S. cyberoperators who are engaged in information warfare, cyberattacks, and espionage outnumbered Russia's by nine to one. 
123
124
125
126
127
128
129
130
131
132
133
Russian military units and other organizations responsible for recent digital information confrontation campaigns targeting the West are mostly headquartered in Russia's two most populous cities, St. Petersburg and Moscow. Two Russian military units responsible for offensive computer-network operations are the GRU's Unit 26165 (the 85th Main Special Service Center) and Unit 74455, both of which are based in Moscow. 
134
135
136
137
Russia employs social media primarily for four general, non-mutuallyexclusive aims (Table 
3
Russia uses social media both to shape the narratives surrounding conflicts and to facilitate operational and tactical activities of Rus- sian forces. 
138
139
140
141
142
143
144
145
146
Russia's social media efforts often are designed to advance Russian foreign-policy narratives in parallel with official statements and traditional media. Much social media-based information activity is intended to deflect criticism; muddy the waters; or defend Russia when the Russian state is accused of wrongdoing, such as accusations by the United Kingdom and the West regarding the Kremlin directing the 2018 poisoning of Skripal, Russian responsibility for the downing of flight MH-17, 148 the multiple doping violations by Russian athletes and 145 "The Russian Offensive . . . ," 2017.
146 "The Russian Offensive . . . ," 2017.
147 Donald N. Jensen, "Russia in the Middle East: A New Front in the Information War?" Jamestown Foundation, December 20, 2017; Louisa Loveluck, "Russian Disinformation Campaign Targets Syria's Beleaguered Rescue Workers," Washington Post, December 18, 2018. The accusations against the White Helmets have been debunked by Bellingcat, among others ("Chemical Weapons and Absurdity: The Disinformation Campaign Against the White Helmets," Bellingcat, December 18, 2018). 
148
149
Russia's social media efforts often aim to drown out the evidencebased accounts with multiple-and often highly implausible and contradictory-stories. For instance, the EU's East StratCom Task Force counted more than 40 different accounts of the Skripal poisoning as of early 2019. 
150
152
154
155
156
157
158
156 Ben Nimmo, "Russian Narratives on NATO's Deployment," StopFake, April 2, 2017. 
157
159
160
161
Apart from shaping foreign policy narratives, Russian social media operations sometimes seek to affect the outcomes of elections, refer-159 Syria Justice and Accountability Centre, "Russia's Twitter Campaign: Influencing Perceptions of the Syrian Conflict," December 12, 2018.
160 
DiResta et al., 2018
, p. 58. 161 Schafer, 2018, p. 6;
DiResta et al., 2018, p. 12. 162
163
164
165
166
167
168
169
170
171
172
173
Russians employed social media to exacerbate social, political, economic, and cultural divisions and sources of internal instability within Western societies and institutions-goals that numerous experts ascribe to Russian influence efforts. 
174
175
176
177
178
179
175
176 
Howard et al., December 2018
, p. 39. 177 DiResta et al., 2018, p. 16
178
180
181
182
183
184
185
To illustrate how Russian actors are using social media, we selectively highlight some of the tactics and techniques that Russian actors have used to date that might be applicable to multiple aims and encompass both overt and covert efforts.
Although Facebook and Twitter have received the lion's share of attention from analysts and U.S. policymakers, Russian social media efforts appear across many different social media platforms. YouTube and Instagram have been particularly prominent. 
186
187
188
189
190
191
192
193
Russian actors sometimes build wholly fictitious individuals, often employing actual persons' photographs for the social media profile. For example, many IRA accounts made up names and identities supplemented with stock or random photos. 
195
197
198
199
200
201
Russia often privileges quantity over quality in operations that involve social media efforts, placing volume over plausibility or consistency of disseminated narratives. 
203
204
205
206
207
Russian actors exploit the vast amounts of data available about social media users to microtarget content to those who are most susceptible to the message. The IRA accounts exploited Facebook's advertising algorithms to microtarget U.S. audiences: One Facebook ad, for instance, "geotargeted several regions in Pennsylvania, then added additional interest targeting to reach 18-to 65-year-olds with the interest 'Donald Trump for President, Job title: Coal Miner,'" with the goal of populating a rally for miners. 
209
210
211
212
213
214
Russia not only produces its own content, it also promotes native content. For instance, the world's biggest neo-Nazi website, The Daily Stormer, was promoted on social media "by a suspected Russian bot network." 216 Likewise, Russian actors offer platforms for fringe or radi- 
211
212
213 See Salvo and Hanlon, 2018. 
214
215
216
218
What happens on social media does not stay on social media-in numerous instances, Russian actors use social media to organize reallife events, such as protests. For instance, one of the most popular IRA Facebook groups, the Heart of Texas, organized a Stop Islamization of Texas rally. 
220
221
222
218
219
24-26, 46. 220
Khusyaynova, 2018, p. 20. 222
ties appear calculated to produce mass panic or disorder: In the 2014 Columbia Chemical Hoax, IRA operators disseminated fake messages about an explosion at a chemical plant in a Louisiana town, complete with numerous fake accounts and fabricated news reports from actual news outlets. 
223
Although the number of what might loosely be described as information social media campaigns waged by Russia is large, some have special relevance to USAF and the U.S. armed forces: those that have focused on the U.S. military, veterans, and their families-all of whom have been a consistent focus of Russian social media-based influence campaigns since at least 2013.
Russian actors have threatened particular individuals, apparently to support Russian foreign policy narratives. The GRU Threat Group-which includes outfits identified as APT28, Sofacy, Sednit, Fancy Bear, and Pawn Storm-used social media to impersonate Islamic State users and intimidate military wives. Several women, likely identified by their public roles on military issues, received individualized death threats on Facebook and Twitter from Cyber Caliphate, a now-defunct loose association of hacking groups that claimed to operate on behalf of ISIL. Cybersecurity experts and intelligence services of at least three Western countries have identified the Cyber Caliphate as one of Russia's proxies. 
224
225
224 "Proof that the military wives were targeted by Russian hackers is laid out in a digital hit list provided to the [Associated Press] by the cybersecurity company Secureworks last year" (Raphael Satter, "Russian Hackers Who Posed as ISIS Militants Threatened Military Wives," Talking Points Memo, May 8, 2018; also see "Threat Group-4127 Targets Google Accounts," Secureworks, June 26, 2016). Generally, that Cyber Caliphate is a Russian operation became "the consensus view among Western intelligence services" (Schindler, 2016). 
225
226
227
228
229
230
231
232
233
234
Russian actors have also sought to expose military and veteran audiences to divisive content and other propaganda. A considerable number of IRA accounts, for example, impersonate individuals with links to the military and then connect to real military audiences on social media. Some accounts attracted thousands of followers-such as the account profiled by Voice of America in the graphic reproduced in Figure 
3
235
232
233
234
235
236
237
238
236
237
238
Proud AMERICAN, wife, mother, conservative, served my country in USMC.
Semper Fi.!, #RedNationRising, https://t.co/LK8io8dsBO, smartchic.me from the Moscow think tank Strategic Culture Foundation. 
239
240
241
242
243
244
239
240 Schreckinger, 2017;
Gordon and Goldstein, 2017. 241
245
246
247
248
Whether and how Russia will wage information warfare on social media in the future depend in large part on how successful it believes it has been in using this tool. The amount of attention and alarm that Russia's information efforts, including those on social media, have attracted might suggest that Russia has been quite successful. Objec- 
245
249
250
251
252
249
252
253
254
255
256
257
258
259
260
261
262
263
264
263
264
Intensifying Russian information warfare has raised increasing alarm among U.S. allies and partners, prompting a variety of national and international responses. A companion report in this series covers the U.S. government and the tech sector responses;
1
We can think of social media-based information operations in terms of stages, from production of the content (which might entail creating or stealing or hacking), the distribution of content through social media channels, and the consumption of content by audiences of social media users. Countermeasures might be aimed at any one or more stages in that chain. 2 Countermeasures might also accomplish the logically prior functions of awareness-raising or institution-building. Table 
4
Countermeasures aimed at the production stage are those that aim to prevent Russian actors from producing or ordering production of content-i.e., creating false or manipulated information or engaging in cyberattacks to obtain protected information. Prevention can mean deterrence by punishment: economic sanctions, diplomatic isolation, 
2
4
5
4 Glenn Herald Snyder, Deterrence and Defense: Toward a Theory of National Security, Princeton, N.J.: Princeton University Press, 1961. The scholarly literature distinguishes between deterrence by denial, which refers to measures taken prior to an attack, and defense, which refers to measures taken once an attack is occurring. However, as prior RAND work points out, this distinction is not very helpful with regard to activities that tend to be continuous rather than to come in discrete attacks. See Bodine-Baron et al., 2018, p. 21. Thus, although some measures are perhaps best viewed as defense, they are treated here as deterrence by denial. ited by use of algorithms that filter out items identified as fake, laws and regulations that prohibit or censor certain content or content creators, and manual processes that filter out disinformation or propaganda.
Measures aimed at the consumption stage seek to build resilience, reduce susceptibility, or inoculate audiences against Russian information operations. Activities that can help meet these goals include debunking (i.e., exposing disinformation or information that is otherwise manipulated) and education, particularly media literacy. Exposing audiences to proactive public diplomacy or positive strategic communication also might reduce susceptibility to disinformation about those subjects. Countermeasures can also be taken to try to reduce the credibility of particular messages or messengers, such as through warnings, tagging of information that is suspected of being false, or identifying particular sources as suspect. 
6
Not all countermeasures are adopted primarily with the Russian threat in mind. Digital identity verifications or comprehensive laws, such as the General Data Protection Regulation, likely make the social media landscape more difficult for Russian actors to navigate, but they also come with trade-offs, the evaluation of which is beyond the ambition of this study.
For the most part, intergovernmental and nongovernmental responses have generally focused on awareness-raising and consumption. Moreover, because the threat of information manipulation on social media is recent and novel, Western governments have devoted considerable effort to institution-building. Countermeasures aimed at the distribution stage tend to be within the province of social media companies. Individual European states' responses vary from virtual inaction to a menu of countermeasures across all categories; here, we highlight only select aspects of these responses.
NATO's most noteworthy institution-building achievement is the 2014 creation of the StratCom CoE in Riga, Latvia. The center advances NATO's operations and counters adversaries' information operations through public diplomacy, civilian and military public affairs, and information and psychological operations. 
7
8
9
10
11
12
13
14
15
16
17
18
19
16
17
November 29, 2018
. 18 Vilmer et al., 2018
, p. 134. 19 European Commission, 2018
. 20 European Commission, 2018. 21 Hybrid CoE, "What Is Hybrid CoE?" webpage, undated.
22
23
These international countermeasures have raised the level of awareness about Russia's social media-based information operations and Western vulnerabilities to these operations. This awareness is essential for the possibility of affecting any other aspect of Russia's information warfare, whether at the production, dissemination, or consumption stages.
NATO's exercise with StratCom CoE, for example, produced important insights. Although many details surrounding the effort remain classified, the replicated adversary was able to gather a great deal of information about the soldiers and track their movements through the experimental social media platforms. 
24
25
26
27
28
29
30
31
32
33
34
35
36
27
28
29
30
31
November 29, 2018. 32
33 Vilmer et al., 2018, p. 130. 34
35 Vilmer et al., 2018, p. 130. 36
37
38
39
40
41
42
European governments' responses to Russian disinformation have varied greatly. The European Values Center for Security Policy, a Czech think tank, illustrates that range through its ranking of European states based on the robustness of their responses to the entire domain of the Kremlin's subversive influence activities. 
45
46
47
48
45
46
47
48 Bentzen, 2018, p. 7;
Vilmer et al., 2018, p. 117.
49
50
51
52
53
54
55
56
Civil society actors often have focused on debunking, and raising awareness of, Russian disinformation and propaganda. By one count, 149 fact-checking websites were active in 2018, though many predate that and/or do not focus exclusively on Russia. 
58
59
A comprehensive assessment of national governmental or civil society responses is beyond the scope of our study. We observe that some of the 
56
57
58 Vilmer et al., 2018, p. 137;
Duke Reporters' Lab, homepage, undated. 59
60
61
62
Arguably the economic and geopolitical linchpin of the EU and a major hub for U.S. forces, Germany ranks among the more-energetic responders to Russia's subversive activities, partly because of a history of Russian activities targeting German audiences. 
63
64
65
62
63
64
66
67
68
69
70
71
72
73
However, there are reasons to moderate faith in the deterrent effect of such countermeasures. As a foreign affairs expert Tyson Barker observes, "compared to the precipice elections in the United States, France, and Italy, Germany's election is shaping up to be a bit of a nonevent," with "the pro-EU and internationalist consensus still hold [ing]  in Germany." 
74 Thus,
"[u]
75
76
On the production side, evidence that Russian actors have been successfully deterred from producing disinformation and propaganda has been generally scant. Even if Russia was deterred from meddling in Germany's 2017 election, some experts were warning by the 2019 EU 
73 Brattberg and Maurer, 2018, p. 20
74
75
76 Schwirtz, 2017
77
78
79
80
81
82
77
78
79
Apuzzo and Satariano, 2019b;
Apuzzo and Satariano, 2019a. 80
81 "The St. Petersburg Troll Factory Targets Elections from Germany to the United States," EU vs. Disinfo, April 2, 2019. 
82 Howard et al., 2018, p. 34.
83
84
85
86
87
88
83
Cohen et al., 2021
. 85 Howard et al., 2018, p. 9. 86
87
89
90
91
92
90
91
92
93
94
95
96
97
93 Helmus et al., 2018, pp. 76-77
94
Paul and Matthews, 2019. 95
97
98
There is no magic bullet to address the threat of Russia's information warfare, but this does not mean that countermeasures have been futile. On the contrary, within a few short years, serious institutions have been founded to confront this threat and Western policymakers are far more familiar with the activities of such actors as the GRU, the IRA, and RT. U.S. efforts to counter disinformation would be well served by continuing efforts to raise awareness-both by the intelligence community and the FBI's foreign influence task force, and within DoD-and to strengthen institutions devoted to this threat, such as the Department of State's Global Engagement Center. Some countries have earned high marks for making their citizens into more-educated consumers of social media. At the same time, there are few reasons to think that any attempts to deter the production or dissemination of disinformation have been particularly successful. This implies the need to presume the persistence of Russia's information activities and craft defensive measures accordingly. Another volume in this series of reports addresses the role that various parts of the U.S. government do and can play in this regard. 
99
Of all the countries targeted by Russian disinformation efforts over the past decade, Ukraine's experiences arguably provide the best window into potential Russian tactics and responses, for three reasons. First, few countries in Russia's near abroad hold as much importance for Russia as Ukraine. Aside from Ukraine's general strategic importance as a buffer between the West and Russia, Ukraine is also home to Russia's Black Sea fleet in Crimea. Even after the 2014 conflict, Russia remains Ukraine's largest export and import market.
1
3
Finally, Ukraine provides a unique example in terms of how to respond to disinformation efforts. Partly because Ukraine views Russia as existential threat, it has employed tactics that other targets of Russian disinformation have yet to do, such as mobilizing civil society, banning use of mobile phones among frontline troops, and even banning an entire social network (VK). 
4
Russian disinformation efforts in Ukraine started long before the 2014 Maidan movement and the ouster of pro-Russian President Viktor Yanukovych and his government. Some themes reiterated in Russian propaganda during the war in the Donbass-for example, that the pro-Western element of Ukraine is made up of fascists-date back at least to the 1990s. 5 Russia's propaganda effort increased in the early 2000s. In 2004, a contested presidential election-mired in accusations of voter fraud-sparked a series of protests, called the Orange Revolution, and ended Yanukovych's first bid for the presidency in favor of Viktor Yushchenko. 
6
7
8
9
10
11
13
14
15
16
17
On November 21, 2013, under Russian pressure, then-President Yanukovych ended discussions of a Ukraine-European Union Association Agreement. 
18
19
14
15
16
17
18
20
Russian disinformation targeted three populations. First and on the broadest level, Russia aimed to discredit the new Ukrainian government internationally, justify Russian actions in Crimea, and frustrate an international response to the unfolding conflict. These efforts ranged from material that painted the fall of Yanukovych as an illegal coup (or a "fascist junta"), Poroshenko as corrupt and illegitimate, and Ukraine as failed state to more-extreme material that linked Ukraine to the Islamic State. 
21
22
23
24
20
Kofman et al., 2017. 21
25
26
27
28
29
30
31
32
33
34
35
36
37
38
31
32
33
34
35
36
37
38
39
40
41
42
[Ukrainian] soldiers receive texts telling them they are "surrounded and abandoned." Minutes later, their families receive a text stating, "Your son is killed in action," which often prompts a call or text to the soldiers. Minutes later, soldiers receive another message telling them to "retreat and live," followed by an artillery strike to the location where a large group of cellphones was detected. 
43
Russia also infiltrated veterans groups' social networks to try to undermine their commitment to fighting in Eastern Ukraine, particularly targeting recently mobilized veterans. 
44
39
40
41
42
45
46
47
48
49
50
Partly because Ukraine viewed the Russian invasion as an existential threat, Ukraine took dramatic steps to respond. Not all of these actions were successful, nor are all these actions necessarily replicable elsewhere. Still, the Ukraine example provides an important case study of how states could respond to the disinformation efforts on both the tactical and strategic levels.
Ukraine has engaged in institution building to better counter information campaigns. On December 14, 2014, Ukraine established a Ministry of Information Policy of Ukraine. Officially, this ministry has three objectives: to "develop strategies for information policy of Ukraine and the concept of information security," to "coordinate government agencies in matters of communication and information dissemination," and to "counteract informational aggression by Russia." 
51
52
53
54
55
56
51
52
53
54
55
56
57
58
59
Because Russian disinformation efforts would often capitalize on Ukrainian misinformation to depict the Ukrainian government as incompetent and the situation as more dire than it actually was, the most basic-but perhaps more important-aspect of the Ukrainian response was enforcing message discipline on the Ukrainian government. In conjunction with the Ukraine Crisis Media Center, the Ukrainian government and military implemented its One Voice Policy to ensure that the Ukrainian government was only putting out one 
57
58
March 8, 2019. 59
narrative. 
60
61
62
63
64
65
66
67
68
69
70
Ukraine also tried to combat disinformation through more-extreme measures. The military banned soldiers' use of mobile phones on the front lines for a mixture of operational security and counterdisinformation reasons, 71 but the most pressing concern likely was Russia targeting soldiers based on their phone locations. 
72
73
68
69
70
71
72
73
74
75
76
77
78
79
5
80
81
82
83
83 Dek, Kononova, and Marchenko, 2019, pp. 45, 57
84
Finally, aside from simply countering Russian disinformation attempts, the Ukrainian military also launched information efforts of their own to influence Russian forces and the separatists in the Donbass. Some of these efforts were relatively benign attempts to undermine the Russian narrative. For example, when the leaders of the breakaway republics Donetsk and Luhansk put out a message that the Ukrainian military was going to ban Victory Day celebrations because of its Soviet origins, the Ukrainian military along the line of contact went to mass media to show that they were allowing the celebrations to go forward. 
85
86
87
More-targeted efforts to induce defections-usually at least partially grounded in reality-proved more effective. According to one 
84 Dek, Kononova, and Marchenko, 2019, pp. 48, 50. 85
86
87
88
89
90
91
88
89
90
91
92
Thanks to Ukraine's counter-disinformation efforts and a shift in the war in the Donbas from an active conflict to a frozen one, Russian disinformation likewise has had to evolve. In general, Russian messaging returned to a softer tone, emphasizing a common Russian-Ukrainian "brotherhood" and blaming a small pro-Western faction for the conflict. 
93
94
95
96
97
98
93
94
95
96
97
98
99
101
Russia also shifted back to more-traditional media for its disinformation campaigns. Specifically, Ukrainian politician and oligarch Viktor Medvedchuk has close ties to Putin and is suspected to have gained control over Ukraine News 1 and over Channel 112, one of Ukraine's largest television networks. 
102
104
105
99
100
101
102
103
104
106
107
108
109
110
111
106
107
108
109
110
111
equipment and trots out lists of so-called experts to attest to this fact. 
112
114
115
116
117
118
119
120
In many ways, Ukraine is a best-case scenario for Russian disinformation. Russia knows Ukraine better and is far more intimately connected to Ukrainian culture, history, and politics than to most other countries. Consequently, Russia might not be able to replicate in another context all of the tactics that it employed in Ukraine. Nonetheless, Ukraine as a case study provides several important insights regarding Russian disinformation tactics on the operational level and illuminates some best practices that USAF and the joint force should consider if the need arises to respond to such activities in the future.
In Ukraine, Russian disinformation campaigns worked through several different media-social media, text messages, agents of influence, and traditional media. When Russia encountered an obstacle in one medium (such as the ban on VK), it simply shifted to another (traditional media). In this sense, Russia proved remarkably versatile in adapting its tactics. Russia also showed that it could coordinate disinformation with other tools of power. Perhaps this is best seen in how Russia used disinformation to enable its efforts to geolocate troop formations in the Donbass and target them through artillery strikes. These examples demonstrate that disinformation might not be a separate realm in the context of conflict; rather, it is integrated into conventional military operations.
Whether sending fake text messages to soldiers' family members or infiltrating veterans' groups, Russia's operations in Ukraine show that it singles out current and former service members and their families for disinformation efforts. As discussed in the previous chapters, Russia has also targeted U.S. service members and their families. Consequently, any response conducted by USAF and the joint force needs to look at the entire military community-not just deployed service members.
In terms of possible responses, Ukraine's experiences show that moreactive measures to counter disinformation by banning mobile phone use by soldiers (or even more-draconian policies, such as banning entire social networks) produce mixed results. Forbidding service members to use mobile phones comes at a cost to troop morale (at the very least) and requires significant amounts of discipline to enforce, raising questions of whether such a policy would be practical, even in highly professional militaries, such as that of the United States. Banning entire social networks also presents significant downsides-even leaving aside free-speech concerns-as shown in Ukraine by the increased concentration of pro-Russian political sentiment on VK and the shifting of Russian information efforts to more widely available traditional media after the ban.
On a more positive front, Ukraine's response shows how efforts to combat disinformation start with limiting misinformation. Although proving its effectiveness remains difficult, Ukraine's One Voice Policy at least minimized Russia's opportunities to exploit the Ukrainian government's confusion. This is an important accomplishment because Russia often based its disinformation on partial facts to lend credibility to its narrative. Russia's disinformation efforts in Ukraine also showed the downsides to secrecy; Russian disinformation would often fill the voids left-deliberately or accidently-by the Ukrainian government and military. For USAF and the joint force, both lessons are relevant: Getting one narrative out in the public early and generally being as transparent as possible are strong and required first steps in fighting any sort of Russian disinformation efforts.
Finally, the Ukraine case study reflects how combating disinformation is not simply a whole-of-government concept but rather a wholeof-society fight. Ukraine experience shows that the nongovernmental sectors might in some cases be better prepared to fight disinformation than the government organizations. There a wealth of talent resident in the private sector (e.g., journalists, sociologists); in addition, factchecking from an outside independent source, such as StopFake, might be considered more credible than material coming from the military or the government. Particularly because Russia and other states also might try to pressure social media companies like they did in Ukraine, NGOs might have more sway with technology companies.
121
USAF has a long history of countering Russian information operations against the United States and its allies. During the Berlin Airlift in 1948, for instance, USAF flew in 13 tons of newsprint daily to combat Soviet propaganda in West Berlin. 
1
Russia can be expected to continue pursuing most of the same goals and targets it has in the past, although new targets and objectives also might appear. As the U.S. intelligence community's 2019 Worldwide Threat Assessment forecasts, Russia's social media efforts will continue to focus on aggravating social and racial tensions, undermining trust in authorities, and criticizing perceived anti-Russia politicians. Moscow may employ additional influence toolkits-such as spreading disinformation, conducting hack-and-leak operations, or manipulating data-in a more targeted fashion to influence U.S. policy, actions, and elections.
2
3
4
On the technological front, the United States should expect moresophisticated phishing and cyberattacks. Malware associated with Russian intelligence has grown more sophisticated and could be used to gain and exploit information for future campaigns similar to the hackand-leak scheme used in 2016. For example, Zebrocy malware (a tool used by the GRU's Fancy Bear hackers), rapidly increased its sophistication in the intervening years. 5 That malware was used to target a wide variety of NATO, Central Asian, and other international targets from 2016 to 2019, including an extensive campaign to exploit interest in Brexit as a means of infecting targeted networks. 6 A prominent U.S.-based cybersecurity firm found that state-sponsored Russian hackers could breach networks "eight times as fast" as the next best adversary, North Korea; the firm's senior Russia investigator concluded that "Russia is really the best adversary." 
7
8
9
Information warfare experts also forecast the increasing use of deepfakes, or highly realistic digital manipulations of audio or video. 
10
Conversely, some adaptations that the United States should expect do not rely on fancy technology. Instead, they consist of simpler ways to evade countermeasures, such as blocked accounts. As Keir Giles warned in 2016,
[a] process of building up of capabilities on social media is visible, in particular in the form of accumulation of trusted social media accounts with large networks and numbers of followers. These accounts are at the present moment not used for any overtly hostile process, but engaged in establishing their credibility, and developing tactics for defeating analytical methods used to identify false personae. In particular these tactics include tailored and sophisticated features which generate followers and interaction from genuine accounts. 
11
[It] employed a new audience-building strategy around more positive themes of black affirmation and black beauty, seemingly to avoid further detection and suspension . . . [U]nlike the older Black Matters, the BM page was keen to redirect traffic to the associated website and its new 'Meet Up' feature rather than to keep its audience engaged on the Facebook platform where its efforts had previously been detected and suspended. It is also after this initial suspension on Facebook that the IRA turned to Google Ads to promote the associated Black Matters U.S. website, with ads leveraging text, image, and video formats. 
12
13
14
15
The recommendations we present are those that we believe to be most relevant to the Air Force Special Operations Command (AFSOC) and the joint force. 
16
The joint force should focus special attention on operations of greatest concern to DoD (e.g., those that target members of the U.S. military and its associates or U.S. and NATO operations). Monitoring of social media must extend beyond Facebook and Twitter. As our overview of Russian social media operations shows, Russians are active across a gamut of online fora. Smaller platforms (e.g., Reddit, Instagram) and non-U.S.-based platforms (e.g., VK) are often more important. As suggested in our Ukraine case study, when Russian actors get pushed out of some social media platforms, they will emerge on others. Furthermore, as we show in Chapter Three, Russian-operated accounts do not behave uniformly but instead adopt a variety of deceptive identities. Monitoring processes should be responsive to the need to detect the variety of tactics and techniques that Russian actors are using on social media.
The joint force might further consider tasking MISO specialists to perform a sort of secondary analysis of Russian information operations to identify and assess the source, content, audience, media, and effect (SCAME analysis) of such operations. 
18
19
Monitoring processes should accommodate a thorough approach to attribution and guard against overattribution. Russia's narratives and messaging resonate with many audiences across the West, and many voices independently echo the Kremlin's talking points. This means that algorithms that merely pick up bots, pro-Russian content, or both on social media are liable to overattribute. More-thorough methods are needed, and-at least at present-this is likely to require human participation to heed contextual clues, such as the rules of thumb offered by DRFLab to distinguish Russian trolls from other trolls. 
20
The training and education of U.S. service members on how to recognize disinformation and other information manipulation by Russian actors should be a top and ongoing priority. Training should extend to the family members of service members, considering Russia's track record of targeting this population. Training should familiarize service members with likely themes, targets, and target audiences of Russian information efforts as presented in Chapter Three. This training should emphasize predictable and common themes of Russian information campaigns relevant to the military, such as disinformation maligning NATO and the Syrian opposition and exploitation of social divisions pertaining to the U.S. treatment of its veterans and the U.S. use of force abroad. Training also should provide an overview of Russian themes that are salient in European countries, especially for service members deploying to the European area of responsibility.
Importantly, training should also emphasize the sheer variety of forms Russian efforts take, appearing across social media platforms and in various disguises. That is, service members should be instructed in vigilance not only with regard to obvious trolls on Facebook or Twitter, but to the variety of accounts across every conceivable social media platform that appear real, including trusted or even personally known sources that might have been hacked or coopted.
Awareness training might be provided at several logical points: for example, it might be included in regular family day briefs and provided to service members and their families deploying to Europe or other areas that have been targeted by Russian espionage or information operations. Training should also go beyond instruction or briefings: Plausible disinformation scenarios can and should be incorporated into military exercises.
As demonstrated in our discussion of the Ukrainian case study (as well as by other experiences, such as the NATO exercise discussed in Chapter Four), mobile phones and unrestrained social media use create a vulnerability, exposing individuals not only to geotracking but also microtargeting. Broad measures, such as banning devices or forbidding the use of social media across the board, are not likely to be effective: Apart from imposing burdensome restrictions on U.S. service members, experience shows that Russian actors adapt to bans and identify alternative channels for information warfare. By contrast, narrowly tailored restrictions, such as limits on the kind of information that might be shared on social media, might not be unreasonable.
Importantly, any restrictions should be accompanied by education and further training about Russia's exploitation of personal information posted on social media. Such training should demonstrate how even modest amounts of personal data can be exploited to manipulate perceptions and behavior. Even if USAF or DoD does not restrict what might be shared on social media, service members and their families should be aware that any such information can be exploited for microtargeting and/or hacking. Arranging for experiments similar to the NATO exercise described in Chapter Four, which demonstrates concretely how social media information can be exploited, might provide a more compelling demonstration than pure instruction. Considering prior attacks (such as Breedlove's hacked email and the interception of the Nuland-Pyatt phone call, both discussed in Chapter Three), persistence in targeting the military, and the increasing sophistication of Russia's technical spearfishing and cyberattack capabilities, it is important to protect against likely attacks against highprofile individuals. Information stolen from high-level officials offers the most cache to information warriors in terms of its potential to spread and influence perceptions. Efforts should be made to go beyond general cybersecurity training and to educate and train these officials to minimize the existence of exploitable information. Although no one can abstain altogether from using mobile phones or internet-based communications, top officials should be encouraged to minimize substantive communications through such channels. This will not prevent hack-and-leak information operations, nor will it completely erase the potential for adverse consequences-content has been previously manufactured by the attackers, and the same can be done again. However, offering little in the way of substantive content to leak does lessen the potential damage by depriving attackers' access to actual-and usually more plausible-information. Actual information-such as the transcript of the phone conversation between Nuland and Pyatt-can be embarrassing to the United States and exploited to buttress Russian narratives about U.S. intentions. 21 By contrast, false information might at times limit the resonance and impact of leaked materials-as appeared to be the case when Emmanuel Macron's campaign inten-tionally used cyber-blurring, or injecting clearly false information in anticipation of a hack-and-leak.
22
Countermessaging to counter specific pieces of disinformation is most effective when it is consistent; in this respect, USAF and the joint force face the difficulty of harmonizing their approach with any parallel efforts by NATO, the EU, and any individual states that might be targeted by Russian disinformation or propaganda. It is likely that the optimal approach involves some actor other than the U.S. military taking the lead in countering specific kinds of disinformation; if so, USAF and the joint force social media presence should reproduce the countermessage to give it broader publicity. Who should take the lead on countermessaging, however, would have to be worked out collab-oratively with NATO and the EU-and ongoing coordination would likely be necessary. As past RAND research points out, it is impossible to make after-thefact corrections to all disinformation pertaining to U.S. and allied militaries authored by Russian actors. 
23
Although USAF and the joint force should build up their own social media capabilities to debunk disinformation pertaining to their own activities, it is advisable to rely on NGOs to do so in other contexts. As Ukraine's experience shows, NGO actors are often better equipped to accurately debunk disinformation and propaganda and to disseminate that information. NGOs' superior familiarity with local settings could enable them to act more expediently and reach broader audiences than might be accomplished by similar efforts by the U.S. military.
Moreover, civil society groups have a likely advantage over state actors-as well as over professional media organizations-in their potential to present credible, nonstate, transparent adjudications of what is fact and what is false. Especially in the context of U.S. culture surrounding speech and the boundaries on government action in this realm, there is a widely held belief that organs of the state should refrain from directly adjudicating truths and untruths.
For several reasons, the recommendations we identify concentrate on countermeasures aimed at awareness-raising and at the consumption stage. Most of the countermeasures aimed at limiting distribution tend to be within the purview of social media companies and subject to potential legal regulation in the future. Measures aimed at preventing production call for policy decisions at the U.S. government level (e.g., sanctions), or their efficacy is largely speculative. Among the latter group are deterrence measures aimed at individual Russian actors, which we identified as potential opportunities for exploitation in Chapter Six. Although there is reason to explore these opportunities, little evidence exists at the moment about the effects of such measures. Considering Russia's prior escalatory behaviors in response to the Western impositions of costs (such as sanctions), these actions need to be carefully assessed.
As we observed in Chapter Two, Russia's approach to social media is, to a significant extent, a product of its own anxieties about the potential effects of the internet and social media. In this appendix, we address the nature of these anxieties in greater detail and identify several of Russia's vulnerabilities that underlie these anxieties. Moscow harbors two main sources of anxiety-the potential of social media to empower domestic opposition and the potential of social media to be exploited by Russia's adversaries to demoralize or gain advantages over its armed forces. Although some of these anxieties are exaggerated, underlying perception of the regime's vulnerability to information flow through social media is not without cause. Neither are those anxieties pertaining to the vulnerability of the military to psychological influence through social media. These vulnerabilities could hypothetically be exploited to encourage dissent and division, but there are multiple reasons to be cautious in this regard. Some vulnerabilities present opportunities for offensive action that carry fewer risks: Targeting individual actors within Russia's information confrontation machinery with tailored messaging, in particular, might present a relatively low-cost, low-risk deterrence measures.
The Putin regime has deep-seated anxieties about the internet generally and social media in particular. As we have noted, Russia's anxieties received a considerable boost from the Arab Spring and the 2011-2012 protests in Moscow, which military thinkers and Russian political leaders attribute, at least in part, to psychological operations organized by the West with the use of social media. 
1
The first source of anxiety resides in the potential of social media to empower domestic opposition-and to facilitate foreign meddling to stoke that opposition. The internet has been used as a forum for opposition figures in Russia, and social media has furnished a potential solution to the collective action problem that regime opponents worldwide face. In Russia's view, social media enables Western powers to meddle in the politics of other countries. Even prior to the rise of social media, many among Russia's elite viewed "transnational media"along with support for civil society and democracy promotion-as one vector of influence whereby the West affected the popular psyche, eroding patriotism and nationalism. 2 It is thus unsurprising that social media would be seen in the same light-i.e., yet another vector the West could use in seeking to undermine Russia's regime.
The Russian state's desire to control-or at least comprehensively surveil-these new forms of communications predates Putin, and its roots lie in the Soviet era. 3 Nonetheless, the Russian government has tolerated a relatively uncontrolled internet-especially in contrast with traditional media-until relatively recently. 4 However, since Putin's reelection in 2012-and especially since the Maidan revolution in Ukraine-Russia has adopted a series of measures aimed at seizing greater control over the virtual domain. As a recent RAND report 1 Sivkov, 2014, p. 2; Nesmeyanov, 2017, p. 7. 
2
Mikryukov, 2016;
and Makarenko, 2017, p. 434. 3
Soldatov and Borogan, 2015. 4
5
6
7
8
9
10
11
13
18
19
20
21
22
23
24
Although Russian anxieties about Western actions are exaggerations bordering on fantasy, the underlying perception of the regime's vulnerability to information flow through social media is not without cause. Opposition to Putin's regime, such as it is, does rely on social media. Thus, social media can be used to distribute content that feeds discontent-as Navalny, Putin's most visible opponent, routinely does. (One of his most successful documentaries, on Prime Minister Dmitriy Medvedev, reached 20 million views on YouTube. 
26
27
• Corruption. The scale of corruption in Putin's Russia is legendary. 
28
29
30
33
35
36
Dobbins et al., 2019, pp. 151-152;
Russian Federation, Russian National Security Strategy, full-text translation, December 31, 2015
. 34 Dobbins et al., 2019
, p. 152. 35 Paul Goble, "2018
Spring Draft Highlights Russia's Demographic Decline," Eurasia Daily Monitor, Vol. 15, No. 54, April 10, 2018
36
37
38
39
40
38
Russia's Military Quadrupled in 2018
, Prosecutors Say," Moscow Times, March 21, 2019. 39
Western countries: Their children could attend other schools; they might be able to own property and vacation in Europe or the United States. The ability to travel might be quite valuable to such individuals and would be compromised by a prospect of a criminal indictment. This vulnerability was implicitly exploited by the recent CYBERCOM action against individual Russian operatives. 
41
Some Western experts advocate an offensive approach to Russia's information operations or political warfare more broadly. For example, Seth Jones of the of Center for Strategic and International Studies argues that "Russia will continue to target the United States at home and abroad until the U.S. government implements a more aggressive offensive information campaign." 42 Such a campaign, according to Jones, would "coerce Russia to curb its information warfare campaign, punish Moscow when these incidents occur, and exploit Moscow's weaknesses and vulnerabilities." 
43
44
41
Barnes, 2018. 42
43
45
First, the West tends to view and treat much of Russia's hostile influence or information operations as an illegitimate way to behave with regard to other states. This appears particularly true of Russia's uses of deception on social media, channeled toward other countries' populations at large outside a military context and focused on those countries' domestic politics. Thus, NATO hesitates to embrace such measures: "NATO doctrine does not foresee the use of covert information operations, such as the use of fake identities, 'bots' and 'trolling', against target audiences and furthermore, psychological operations in general can only be used in the context of a military operation declared by the North Atlantic Council." 
46
47
48
45 Dobbins et al., 2019, p. 163
46
47
48
49
50
51
52
53
49
50
April 15, 2016. 51
52 Dobbins et al., 2019, p. 161
53 Dobbins et al., 2019, p. 160.
54
55
56
57
54 Dobbins et al., 2019, pp. 138, 160
55 Dobbins et al., 2019, p. 138. 56
57
Barnes, 2018. 58
Such approaches are unlikely to deter the Kremlin or the Russian military from waging information warfare on social media. However, these approaches might deter individual actors and thus weaken Russia's informational arsenal. Since 2014, Russian officials-notably Prime Minister Medvedev and Deputy Prime Minister Dmitriy Rogozinhave pointed to "brain drain" as a critical national problem. 
59
Informational Arms: Realities and Possibilities ['Троянский конь' XXI века. Информационное оружие: реалии и возможности]," Red Star [Красная звезда], No. 282, August 12, 1995.
17
информационной безопасности в деятельности войск (сил)]," Orienteer [Ориентир], No. 11, November 2001; and V. Belous, "Weapons of the 21st Century [Оружия XXI века]," International Life [Международная Жизнь], No. 2, 2009.
Independent Military Review [Независимое военное обозрение], January 15, 2016; Vladimir Nesmeyanov, "Can We Defend the Great Victory? [Сумеем ли Защитить Великую Победу?]," Flag of the Motherland [Флаг Родины], No. 60, 2013.
32 Valeriy Gerasimov, "The Value of Science Is in Prediction [Ценность науки в предвидении]," Military-Industrial Courier [Военно-промышленный курьер], No.
32 Valeriy Gerasimov, "The Value of Science Is in Prediction [Ценность науки в предвидении]," Military-Industrial Courier [Военно-промышленный курьер], No.
5
97 Anatoliy Tsyganok, "The First Casualties of New-Generation Weapons [Первые Жертвы Оружия Нового Поколения]," Independent Military Review [Независимое военное обозрение],
97 Anatoliy Tsyganok, "The First Casualties of New-Generation Weapons [Первые Жертвы Оружия Нового Поколения]," Independent Military Review [Независимое военное обозрение],
99 "
99 "
115 U.S. Attorney's Office, Eastern District of Virginia, "Russian National Charged with Interfering in U.S. Political System," news release, October 19, 2018.
SOURCE:
SOURCE:
247  
247  
251
This report was completed before the creation of the U.S. Space Force and therefore uses the name "U.S. Air Force" to refer to both air and space capabilities.
Office of the Director of National Intelligence (ODNI), Background to "Assessing Russian Activities and Intentions in Recent US Elections": The Analytic Process and Cyber Incident Attribution, January 6
, 2017, p. 6.2  The IRA is a now-infamous troll farm-a team of trolls, or bloggers and social media operators that disseminate messaging favorable to a sponsoring organization, typically for a fee. These groups are also referred to as troll factories. 3 For an overview of indictments, see Robert S. Mueller III, Report on the Investigation into Russian Interference in the 2016 Presidential Election, Vol. I, Washington, D.C.: U.S. Department of Justice, March 2019, pp. 174-180. 4 For evidence of continued growth in Russia's information warfare on social media, see Philip Howard, Bharath Ganesh, Dimitra Liotsiou, John Kelly, and Camille François, The IRA, Social Media and Political Polarization in the United States, 2012-2018, University of Oxford: Computational Research Project, December 2018.
As the intelligence community assessed, "Russian intelligence services would have seen their election influence campaign as at least a qualified success because of their perceived ability to impact public discussion" (ODNI, 2017, p. 5).
This report was completed before the creation of the U.S. Space Force and therefore uses the name "U.S. Air Force" to refer to both air and space capabilities.
Ulrik Franke, War by Non-Military Means: Understanding Russian Information Warfare, Kista, Sweden: Swedish Defense Research Agency, March 2015, p. 10.
We specify these activities as "likely" to accommodate the fact that intent can be exceedingly difficult to infer based on observable evidence.
The distinction between "information confrontation" and "information war" in the Russian understanding is "the subject of detailed debate in official Russian sources" that is "of little practical impact for assessing Russian approaches"(Giles, 2016, p. 6). To avoid wading into unnecessary terminological debates, we avoid the term "information war" unless it appears in an original source.
  12  In Joint Publication 3-13, the Joint Chiefs of Staff defines information operations as, "[t]he integrated employment, during military operations, of information-related capabilities in concert with other lines of operation to influence, disrupt, corrupt, or usurp the decisionmaking of adversaries and potential adversaries while protecting our own" (Joint Chiefs of Staff, Information Operations, Joint Publication 3-13, Washington, D.C., November 27, 2012, incorporating change 1, November 20,
2014).13  Richard H.Shultz and Roy Godson, Dezinformatsiya: Active Measures in Soviet Strategy,  Washington, D.C.: Pergamon-Brassey, 1984, p. 41.   
For example, see Olga Oliker, "Russia's New Military Doctrine: Same as the Old Doctrine, Mostly," Washington Post,
January 15, 2015.
  4 Giles, 2016, p. 4
.5  Giles, 2016, p. 4; Tony Selhorst, "Russia's Perception Warfare: The Development of Gerasimov's Doctrine in Estonia and Georgia and Its Application in Ukraine," Militaire Spectator,Vol. 185, No. 4, 2016, p.
151.6  Giles, 2016, p. 9, quoting an "authoritative Russian textbook."
Howard et al., 2018, p. 9.    
Howard et al., 2018, p. 9.    
Rohan Smith, "Columbia Chemical Hoax Tracked to 'Troll Farm' Dubbed the Internet  Research Agency," News.com, June 4, 2015.    
Ellen Nakashima, "Inside a Russian Disinformation Campaign in Ukraine in 2014," Washington Post,
December 25, 2017b.
For example, the Russian Institute for Strategic Studies (RISI) is a state-founded think tank, led by retired foreign intelligence officials. According to some U.S. officials, RISI created the framework for interference with the U.S. presidential election. "Putin-Linked Think Tank Drew up Plan to Sway 2016 US Election-Documents," Reuters, April 19, 2017.
Daniil Turovsky, "Our Time to Serve Russia Has Arrived [Пришло наше время послужить России]," Meduza, August 7, 2018a. Other freelancers are oligarchs-such as Konstantin Malofeev, a Russian businessman with ties to the Kremlin who was implicated in a scheme to fund anti-Ukrainian rallies and protests in Poland (Aleksey Dzikavitskiy and Yaroslav Shimov, "Knights of the 'Russian World' [Рыцари «русского мира»]," Radio Svoboda [Радио Свобода], March 2, 2017).
  15  For example, the Siberian Network Brigade, a group of students at Tomsk University that supported Russia during and after the Second Chechen War, provides a clear example of activists who operated without direct guidance from the Russian state, at least at the outset. Turovsky, 2018a. The pro-Russian blog Stalkerzone.org is also "not directly funded by the Kremlin," but is "run by Oleg Tsarov, a pro-Russian separatist in eastern Ukraine" (Bret Schafer, View from the Digital Trenches-Lessons from Year One of Hamilton 68, Washington, D.C.: The German Marshall Fund of the United States, November 19, 2018, p. 9). Another example is South Front, a military affairs website registered in Moscow in April 2015, that has consistently published articles that reinforce Kremlin messaging; at least one expert (in the U.S. State Department) claimed that it was linked to the state (Ben Schreckinger, "How Russia Targets the U.S. Military," Politico Magazine, June 12, 2017). For a detailed account of how Russian criminals supported Kremlin efforts in both technical and psychological cyberoperations, see Daniil Turovsky, Invasion: A Short History of RussianHackers [Вторжение: Краткая История Русских Хакеров], Moscow: Inviduum Publishing [Индивидуум паблишинг],
2019.
16
Mark Galeotti, Controlling Chaos: How Russia  Manages its Political War in Europe, London, United Kingdom: European Council on Foreign Relations, September
20 See Constanze Stelzenmüller, "The Impact of Russian Interference on Germany's 2017 Elections," testimony presented before the U.S. Senate Select Committee on Intelligence, June 28, 2017; and Naja Bentzen, Foreign Influence Operations in the EU, Brussels, Belgium: European Parliamentary Research Service, July 2018, p. 5. 21 Euan McKirdy, "Putin: 'Patriotic Russian Hackers May Have Targeted U.S. Election," CNN, June 2, 2017.22 Andrew E. Kramer, "How Russia Recruited Elite Hackers for Its Cyberwar," New York Times, December 29, 2016.23 Stelzenmüller, 2017; Mark Galeotti, "The 'Trump Dossier,' or How Russia Helped America Break Itself," Tablet Magazine, June 13, 2017b.   
This is especially true for the information-technical component of these efforts, which falls on the shoulders of a wide array of partners. For a snapshot of Russia's efforts to corral public and private enterprises to conduct cyberoperations, see
Kramer, 2016;
Defense Intelligence Agency, Russia Military Power: Building a Military to Support Great PowerAspirations, Washington, D.C., 2017, p. 74.    
"Special Front [Особый фронт]," Arguments of Time [Аргументы времени], October 1, 2018.
Nikolay Pushkarev, "The Activities of Military Intelligence During the Fall of the Soviet Union [Деятельность военной разведки в период Распада СССР]," GRU: Inventions and Reality [ГРУ: вымысли и реальность] Moscow: Eksmo [Эксмо], 2004; "Special Front . . ." 2018.
Troianovski and Nakashima, 2018.
U.S. Department of Justice, Office of Public Affairs, "U.S. Charges Russian GRU Officers with International Hacking and Related Influence and Disinformation Operations," press release, October 4, 2018.
30
Pavel Luzin, "How Successful Is Russia's Military Propaganda Media?" Moscow Times,  July 10, 2019.    
Zvezda consistently fails to make the top 100 most-popular television channels.
Luzin, 2019.
The latter was reported to have 87,000 subscribers and slightly more than 17 million views as of summer of 2019.
Luzin, 2019.
Luzin, 2019.
"Cyber-Forces Will Appear in the Army Before the End of the Year [Кибервойска появятся в армии до конца года]," Moscow 24[Москва 24], July 5, 2013; "Russia Is Creating a Cyber-Force [Россия создает кибервойска]," Military Review [Военное обозрение],
August 8, 2013.
Pete Earley, Comrade J: The Untold Secrets of Russia's Master Spy in America After the End of the Cold War, New York:Berkley, 2006, p. 194.    
Yevhen Fedchenko, "Kremlin  Propaganda: Soviet Active Measures by Other Means," Stopfake.org, March 21, 2016.
Miriam Elder, "Emails Give Insight into Kremlin Youth Group's Priorities, Means and Concerns," The Guardian,February 7, 2012a.    
"Temnik-the Kremlin's Route to Media Control," EU vs. Disinfo, March 29, 2017; Dmitriy Skorobutov, "Confession of a Propagandist. Part I. How to Make News on Government TV [Исповедь пропагандиста. Часть I. Как делают новости на государственном ТВ]," The Insider, June 9, 2017. Also see Peter Pomerantsev, Nothing Is True and Everything Is Possible: The Surreal Heart of the New Russia, New York: PublicAffairs, 2015. Additionally, as ODNI, 2017, recounts,According to Simonyan, Gromov oversees political coverage on TV, and he has periodic meetings with media managers where he shares classified information and discusses their coverage plans. Some opposition journalists, including Andrey Loshak, claim that he also ordered media attacks on opposition figures.
69
2017.70 ODNI, 2017, p. 9; "EU Releases New Sanctions List," Radio Free Europe/Radio Liberty, July
30, 2014.   71
 ODNI, 2017.   72 ODNI, 2017.   
"In the Footsteps of the GRU Officers. New Details in the 'Case of Russian Hackers' [По следам офицеров ГРУ. Ровые детали в «деле русских хакеров»]," Radio Svoboda [Радио Свобода], July 17, 2018.
Alexander I. Kolpakidi and Dmitry P. Prokhorov, "Military Intelligence and the Epoch of Détente [Военная разведка и эпоха разрядки]," Militera.lib.ru, undated.
Twitter, "Data Archive," webpage, undated.
Much of the content was apolitical in a likely attempt to gain credibility with followers. Darren L. Linvill and Patrick Warren, "Russian Trolls Can Be Surprisingly Subtle, and Often Fun to Read," Washington Post,September 10, 2018.  
118 United States ofAmerica v. Viktor Boris Netyksho, Boris Alekseyevich Antonov et al., U.S.C. § § 2, 371, 1030, 1028A, 1956, and 3551 et seq., United States District Court for the District of Columbia, July 13, 2018; U.S. Department of Justice, Office of Public Affairs, 2018; DFRLab,
2018e.119  DFRLab, "Top Takes: Suspected Russian Intelligence Operation," Medium, June 22, 2019.
For instance, CYBERCOM alone consists of 133 teams and 6,200 personnel, which overshadows even the high-end German estimate of Russia's offensive cyber warrior ranks at 4000 (see the "State Actors" portion of the section titled "People" earlier in this chapter). DoD, "Cyber Mission Force Achieves Full Operational Capability," May 17, 2018. For a sense of perspective regarding the numbers of PSYOPS officers, see Jeff Gerth, "Military's Information War Is Vast and Often Secretive," New York Times,
December 11, 2005.
In 2015, CYBERCOM's budget was $509 million. Michael S. Rogers, testimony presented before the Senate Committee on Armed Services, Washington, D.C., March 19, 2015; Sean D. Carberry, "CyberCom Seeks 16 Percent Budget Surge for 2018," FCW, May 23, 2017. For fiscal year 2020, $532 million was reportedly to go to support cyberoperations, with another $1.9 billion earmarked for new buildings and infrastructure. Aaron Boyd, "What DOD Plans To Do With $9.6 Billion in Cyber Funding," Nextgov, March 14, 2019. The estimates for Russia's expenditures on some indeterminate subset of activities likely by state actors are in the $300 million range (see the "State Actors" portion of the section titled "Money" earlier in this chapter).
See the "State-Affiliated Actors" portion of the section titled "Money" earlier in this chapter for a breakdown of Russia's budget.For  USAGM budgets, see U.S. Advisory Commission on Public Diplomacy, 2018 Comprehensive Annual Report on Public Diplomacy and International Broadcasting, Washington, D.C.: U.S. Department of State, November 20, 2018, p. 32.
See Nikolai Litovkin, "Russia's Cyber Army Hacks a Spot in the Top 5," Russia Beyond the Headlines, January 12, 2017.
China's cybertroops numbered 20,000, with an annual budget of $1.5 billion, and the United Kingdom was assessed to have 2,000 cybertroops and annual financing of $450 million.
Litovkin, 2017.
  125  The survey attracted significant attention in the Russian press and stirred debate regarding both methodology and how data were acquired, but most of the doubt seemed to sur-
"Editor-in-Chief of RT Commented on Power's Statement on the Budget of the Channel [Главный редактор RT прокомментировала слова Пауэр о бюджете телеканала]," RIANovosti, January 18, 2017.
Howard et al., 2018, Table 4.    
It is possible that the organization was able to generate revenue through its own merchandise promotion through Instagram, though no sales data are available and merchandising might have simply provided a means to gather consumer information.DiResta et al., 2018,  pp. 29-31.  
  129  ReneeDiresta and Shelby Grossman, Potemkin Pages & Personas: Assessing GRU Online  Operations, 2014-2019, Stanford, Calif.: Internet Observatory, Cyber Policy Center, Stanford University, white paper, 2019, p. 47.   
Andy Greenberg, "Alphabet-Owned Jigsaw Bought a Russian Troll Campaign as an Experiment," Wired, June 12, 2019b.
"KL Calculated the Average Cost of Custom DDoS-Attacks [ЛК подсчитала среднюю стоимость заказной DDoS-атаки]," SecurityLab,
March 24, 2017.
"KL Calculated . . . ," 2017.    
In 2015, two Russian businessmen probably connected to the Kremlin revealed the cost of the DDoS attacks that were allegedly leveled by an independent programmer against the Ukrainian defense ministry's website.
Kramer, 2016
Turovsky, 2019.
"In the Footsteps . . . ," 2018.
Moscow-Russia.ru, "Military University of the Ministry of Defense of the Russian Federation [Войнный университет министерсвта обороны Российской Федерации]," webpage, 2019.
  136  For examples of the relationship between cyber units and Russian academia, see Peter Mironenko and Anastasia Yakoreva, "Cryptographers from Military Units: What We Know About the Accused Russian Hackers," The Bell,
July 14, 2018;
Kovalev and Bodner, 2017;
Kevin Poulsen, "
163.137  Chen, 2015; Virtual Globetrotting, "MediaSintez LLC-Division of Internet Research Agency-Russian 'Troll Farm,'" webpage, undated.
For further discussion of Russia's use of information efforts in the prelude to its annexation of Crimea, see Michael Kofman, Katya Migacheva, Brian Nichiporuk, Andrew Radin, Olesya Tkacheva, and Jenny Oberholtzer, Lessons from Russia's Operations in Crimea and Eastern Ukraine, Santa Monica, Calif.: RAND Corporation,RR-1498-A, 2017, pp. 12-16,  28-29, and 50-54.  
139 Mark Laity, "Chief Strategic Communications at SHAPE: 'Perception Becomes Reality,'" presentation, October 2014 (quoted inGiles, 2016, p.
46)
April 20, 2018.   141  Aaron Brantly and Liam Collins, "A Bear of a Problem: Russian Special Forces Perfecting Their Cyber Capabilities," Association of the United States
Army, November 28, 2018.   142  
Trioianovski and Nakashima, 2018.   143  Russian Defense Ministry [Минобороны России], @mod_russia, Twitter account, undated.
Jack Stubbs, "#NoRussiaNoGames: Twitter 'Bots' Boost Russian Backlash Against Olympic Ban," Reuters,
December 8, 2017.
"Year in Review: 1001 Messages of Pro-Kremlin Disinformation," EU vs. Disinfo, January 3, 2019.
Sarts, 2017, p. 31. Also see European Commission, "A Europe That Protects: The EU Steps Up Action Against Disinformation," press release, December 5, 2018.
Joseph Menn, "Exclusive: Russia Used Facebook to Try to Spy on Macron Campaign-Sources," Reuters,
July 27, 2017.
 170  Matthew Field and Mike Wright, "Russian Trolls Sent Thousands of Pro-Leave Messages on the Day of Brexit Referendum, Twitter Data Reveals," The Telegraph,October 17,  
2018. 171 Digital, Culture, Media and Sport Committee, Digital, Culture, Media and Sport Committee, Disinformation and 'Fake News': Interim Report, London, United Kingdom: United Kingdom House of Commons, Fifth Report of Session 2017-19,
July 29, 2018.   172  Spanish intelligence confirmed that social media was used by Russian-based groups to spread misinformation, although the involvement of the government cannot be confirmed. See Vasco Cotovio and Emanuella Grinberg, "Spain: 'Misinformation' on Catalonia Referendum Came from Russia," CNN
,
November 14, 2017.
United States v. Khusyaynova, 2018, p. 13.   
Interview with Ukrainian security experts, Kyiv, Ukraine, March 6, 2019.
Nakashima, 2017a.    
Martin Innes, "Russian Influence and Interference Measures Following the 2017 UK Terrorist Attacks," Cardiff University Crime and Security Research Institute, December 18, 2017.
183 Stefan Meister, "The 'Lisa Case:' Germany as a Target of Russian Disinformation," NATO Review Magazine,
2016.184 Joe Parkinson and Georgi Kantchev, "Document: Russia Uses Rigged Polls, Fake News to Sway Foreign Elections," Wall Street Journal, March
23, 2017.    185 "Behind the Dutch Terror Threat Video: The St. Petersburg'Troll Factory' Connection,"  Bellingcat, April 3, 2016.   
Paresh Dave and Christopher Bing, "Russian Disinformation on YouTube Draws Ads, Lacks Warning Labels: Researchers," Reuters,
June 7, 2019;
December 17, 2018.
Rosenberger, 2018. Regarding Reddit, see Benjamin Plackett, "Russian Spam Accounts Are Still a Big Problem for Reddit," Engadget, April 2, 2019.
Rosenberger, 2018; interview with NGO expert, Washington, D.C., February 21, 2019.   Regarding the particularly prominent role of Instagram in the United States, see
Martineau, 2018.
Interview with NGO expert, Washington, D.C., February 21, 2019; also see Nina Jankowicz, "How the U.S. Can Fight Russian Disinformation for Real," Atlantic Council blog post,
July 11, 2019.
Nitin Agarwal and Kiran Kumar Bandeli, Examining Strategic Integration of Social Media Platforms in Disinformation Campaign Coordination, Defence Strategic Communications, Vol. 4, Spring 2018e.
United States of America v. Viktor Boris Netyksho, Boris Alekseyevich Antonov et al., case 1:18-cr-00215-ABJ, July 13, 2018.
Ryan Broderick, "Here's Everything the Mueller Report Says About How Russian Trolls Used Social Media," BuzzFeed News, April 18, 2019.
According to DFRLab analysis, this might have provided operational security, but it did severely limit the impact of the operation: The profiles failed to gain traction with other users because of their short existence. DFRLab, 2019.
Nakashima,  
2017b.201  These groups attracted on the order of 200,000 to 300,000 followers each before Facebook took them offline. See
Broderick, 2019
The incidents predated Russian military involvement in Syria, but Russia has been supporting President Assad since the early stages of the conflict, presenting his regime as the only force strong enough to overcome the terrorist threat.
227 "Most of the material was labeled "FOUO," which means "For Official Use Only," but none of it appeared to be classified or sensitive information." Lolita C. Baldor, "Key US Military Command's Twitter, YouTube Sites Hacked," APNews, January 12, 2015; also seeSchreckinger,  
2017. 228 Michael S. Schmidt and Helene Cooper, "ISIS Urges Sympathizers to Kill U.S. Service Members It Identifies," New York Times, March
21, 2015. 229 Pierluigi Paganini, ISIS Cyber Capabilities, Madison, Wisc.: Infosec Institute,
May 9,  2016.    230 Michael Riley, "Russian Hackers of DNC Said to Nab Secrets from NATO, Soros," Bloomberg,
August 11, 2016;
Schreckinger, 2017.
Alice Donovan, "Does America Need Such Friends," Veterans Today,
February 25, 2016.
DiResta et al., 2018, p. 11.    
United States v. Khusyaynova, 2018.   
For example, a study of Russia's effects on electoral outcomes finds "little evidence thus far that Russia has had much of an impact on Western democracies." Lucan Ahmad Way and Adam Casey, Stanford University, Is Russia a Threat to Western Democracy? RussianIntervention in Foreign Elections, 1991-2017, Stanford, Calif.: Stanford University, November 3, 2017.  
  254  The absence of proverbial natural experiments makes it difficult to isolate causes of particular opinions or behaviors. When it comes to the observed effects of Russian television, for instance, the impact of Russian broadcasts is tough to discern because people who already harbor pro-Russian sentiments are more likely to seek out Russian television channels to begin
with.255  For example, see Way and Casey,
2017, p. 1.   256  This appears to have been achieved in part by buying advertisements to boost the popularity of the material.
Nakashima, 2017b.   257  As DFRLab found regarding an information campaign (dubbed Secondary Infektion) that it attributes to Russian intelligence, "almost none of the operation's stories had significant traction." See DFRLab, 2019.
Matthew Rosenberg, Charlie Savage, and Michael Wines, "Russia  Sees Midterm Elections as Chance to Sow Fresh Discord, Intelligence Chiefs Warn," New York Times,February 13,  2018.    
David Ignatius, "Russia's Radical New Strategy for Information Warfare," Washington Post, January 18, 2017.
Aleksandr Dvornikov, "Headquarters for New Wars [Штабы для новых войн]," Military-Industrial Courier [Военно-промышленный курьер], No. 28, July 24, 2018.
261 Jean-Baptiste Jeangène Vilmer, The "Macron Leaks" Operation: A Post-Mortem, Washington, D.C.: Atlantic Council, June 2019, p
. 21.262  Interview with academic, Washington, D.C.,February 11, 2019. For an example of likely publicity-seeking pronouncements of success, see Scott Stedman, "Kremlin Propagandist Boasted of His Hacking Efforts, Strongly Implied Colluding with Trump Team in Facebook Posts," Medium, November 21, 2017.
See Raphael S. Cohen, Nathan Beauchamp-Mustafaga, Joe Cheravitch, Alyssa Demus, Scott W. Harold, Jeffrey W. Hornung, Jenny Jun, Michael Schwille, Elina Treyger, Nathan Vest, Combating Foreign Disinformation on Social Media: Study Overview and Conclusions, Santa Monica, Calif.: RAND Corporation, RR-4373/1-AF,
See, for example, Digital, Culture, Media and Sport Committee, 2018, p. 85.   
NATO StraCcom CoE, "About Strategic Communications," webpage, undated.    
For example, Bay et al., 2019, presents  several studies and research related to Russian information operations. And further institution-building is afoot: In 2018, officials endorsed a framework to stand up a NATO Intelligence Academy. See NATO, "Allied Intelligence Chiefs Discuss Countering Cyberattacks, Disinformation,"November 29, 2018.    
Vilmer et al., 2018, p. 135.   
Deutsche Welle, "Russia's Information Warfare Targets German Soldiers in Lithuania," Atlantic Council,
February 24, 2017.
Bentzen, 2018
June 27, 2019.
European Commission, Joint Communication to the European Parliament, the European Council, the Council, the European Economic and Social Committee and the Committee of the Regions: Report on the Implementation of the Action Plan Against Disinformation, Brussels, June 14, 2019.
Lapowsky, 2019. For the full study, see
Bay et al., 2019.
Lapowsky, 2019.    
Vilmer et al., 2018, p. 130.   
Cohen et al., 2021.   
Russian trade accounted for 9.2 percent of Ukraine's exports and 14.5 percent of Russia's imports in
Central Intelligence Agency, "Europe: Ukraine," World Factbook website, undated.2 Based on 2018 estimates, Central Intelligence Agency, undated.3 As one Ukrainian journalist put it, "Ukraine is the petri dish for Russian disinformation efforts." Interview with a Ukrainian journalist, Kyiv, Ukraine, March 5, 2019.
Interview with a Ukrainian media expert, Kyiv, Ukraine, March
5, 2019.5  Interview with a Ukrainian journalist, Kyiv, Ukraine, March 5, 2019.6  Interview with a Ukrainian journalist, Kyiv, Ukraine, March 5, 2019.
These websites included Novorus, homepage, undated; and novorossia.ru, homepage, undated (website no longer active). SeeReynolds, 2016, p. 25.    
Interview with a Ukrainian politician, Kyiv, Ukraine, March 5, 2019.
Interview with a think tank analyst, Kyiv, Ukraine, March 5, 2019.
Interview with Ukrainian security officials, Kyiv, Ukraine, March 6, 2019.
See Cohen et al., 2021.   
Daniel F. Harrington, Berlin on the Brink: The Blockade, the Airlift, and the Early Cold War, Lexington, Ky.: University Press of Kentucky,
2012, p. 112.   
Daniel R. Coats, Worldwide Threat Assessment of the US Intelligence Community, Washington, D.C.: Office of the Director of National Intelligence, January 29, 2019.
3 Andrew E. Kramer, "Russian General Pitches 'Information Operations as a Form of War," New York Times, March 2, 2019
.4  For example, see the prognosis by Lithuania's president, Dalia Grybauskaite: "What we see is a steadily growing pressure on cyber, the information front, propaganda and, recently, fake news . . . [t]heir efforts and instruments are becoming more sophisticated every day"(Barnes,  
2018).5 "Russian Nation-State Hacking Unit's Tools Get More Fancy," Oodaloop, May
24, 2019.   6  Charlie Osborne, "Fancy Bear Exploits Brexit to Target Government Groups with Zebrocy Trojan," Zero Day,
December 14, 2018.
Andy Greenberg, "Russian Hackers Go From Foothold to Full-On Breach in 19 Minutes," Wired, February 19, 2019a.   
Howard et al., 2018, p. 10. The final touch to this tactic was that "[f]ollowing the initial suspension of the Black Matters Facebook page, the IRA also leveraged the Black Matter US Twitter account to complain about its suspension on the platform and to accuse Facebook of 'supporting white supremacy.'"
Michael Shwirtz and Sheera Frenkel, "In Ukraine, Russia Tests a New Facebook Tactic in Election Tampering," New York Times,
March 29, 2019.
International Strategic Action Network for Security (iSANS), presentation at RAND Corporation, Washington, D.C., April 23, 2019.
Private Facebook groups and encrypted messengers; interview with Belarus experts, Washington, D.C.,June 19, 2019;
Jankowicz, 2019.
These recommendations articulate what we conclude are best practices and are not intended to identify AFSOC, USAF, or DoD capability gaps.
For more information on SCAME analysis, see Department of the Army, "Appendix D: Propaganda Assessment," Tactical Psychological OperationsTactics, Techniques, and Procedures, Field Manual 3-05.302 MCRP 3-40.6B, October 2005.  
19 Amy Sexhauer, Victor Mckenzie, Shari Smith, and Philip Kautz, "Optimizing Indirect MISO: MIST-Iraq and Advising at the Operational Level of War," Special Warfare, January
-March 2018, p. 32.   
DFRLab, "#TrollTracker: How to Spot Russian Trolls," Medium,
March 29, 2018b.
For example, see Doina Chiacu, and Arshad Mohammed, "Leaked Audio Reveals Embarrassing U.S. Exchange on Ukraine, EU," Reuters, February 6, 2014.
This was done intentionally by Macron's presidential campaign in anticipation of the attack, which experts cite as a contributing factor to Russia's failure in its campaign to undermine Macron's candidacy. SeeVilmer, 2019.   
Helmus et al., 2018, p. 88.   
Dobbins et al., 2019.
For a discussion of these laws, seeReynolds, 2016, p. 23.    
Reynolds, 2016, p. 24.    
Lysenko, Yakov, "Terrorists Used Telegram [Террористы использовали Telegram]," Gazeta.Ru,
April 27, 2018.
Andrey Kartapolov and Oleg Falichev, "The Army Should Be Spiritual [Армия должна быть духовой]," Defense and Security [Защита и безопасности], No. 4, 2018.
Sergey Sukhankin, "Military Psychology-New Pivot of Russian Military Strategy," RealClearDefense,March 15, 2018.    
Sukhankin, 2018.
Julia Ioffe, "What Russia's Latest Protests Mean for Putin," The Atlantic, March
27,
27
For evidence that experience of corruption affects Russians' opinions of the regime, see William M. Reisinger, Marina Zaloznaya, and Vicki L. Hesli Claypool, "Does Everyday Corruption Affect How Russians View Their Political Leadership?" Post-SovietAffairs, Vol. 33, No. 4,  2017, pp. 255-275
.
30
2017.31  For example, see Elizaveta Fokht, "Russia and Putin: Is President's Popularity in Decline?" BBC, June
19, 2019.   32  On the tensions inherent in Russian national identity, see Yuri Teper and Daniel D. Course, "Contesting Putin's Nation-Building: The 'Muslim Other' and the Challenge of the Russian Ethno-Cultural Alternative,"Nations and Nationalism, Vol. 20, No. 4, 2014.   
The IRA appears not to vet their employees thoroughly for patriotism or devotion to the cause of information warfare. For example, see J. J. Green, "Tale of a Troll: Inside the 'Internet Research Agency' in Russia," WTOP, September 17, 2018; Neil MacFarquhar, "Inside the Russian Troll Factory: Zombies and a Breakneck Pace," New York Times, February 18, 2018.
"Medvedev Named the 'Export of Intellect' from Russia as Unacceptable [Медведев назвал недопустимым «экспорт интеллекта» из России]," RBC [РБК], February 27, 2017; "Rogozin Urged to Stop the "Brain Drain" Abroad [Рогозин призвал остановить «вымывание мозгов» за рубеж]," RBC [РБК], February 27, 2018.
Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv Abbreviations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii
Many people contributed to the completion of this report. We are grateful to the people who arranged and participated in interviews in Ukraine and the 
United States
Andrew Radin
Donald Jensen
Dara Massicot
Chris Paul. Any
prepared under contract 
FA7014-16-D-1000
Air Force Special Operations Command APT Advanced Persistent Threat CYBERCOM U.S. Cyber Command DDoS distributed denial of service DFRLab Digital Forensics Lab DNC Democratic National Committee DoD U.S. Department of Defense EU European Union
FSB Federal Security Service (Russian Federation) GRU Russian Military Intelligence GOU Main Operational Directorate IRA Internet Research Agency IT information technology ISIL Islamic State of Iraq
NATO North Atlantic Treaty Organization NGO nongovernmental organization ODNI Office of the Director of National Intelligence OK Odnoklassniki PSYOPS psychological operations xviii Russian Disinformation Efforts on Social Media StratCom CoE Strategic Communications Centre of Excellence SVR Foreign Intelligence Service (Russian Federation) UK United Kingdom USAF U.S. Air Force USAGM U.S. Agency for Global Media VK
of units, and in some cases-to its complete loss," according to military authors writing for the journal Military Thought. 
14
15
16
17